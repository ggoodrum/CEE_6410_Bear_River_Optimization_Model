dat.dm
dat.lm.ME2 <- lm(do.avg ~ (S + D + L + FL)^2, data = dat.dm)
summary(dat.lm.ME2)
dat.lm <- lm(do.avg ~ (S + D + L)^3, data = dat.dm)
summary(dat.lm)
dat.lm.ME2 <- lm(do.avg ~ (S + D + L + FL)^2, data = dat.dm)
summary(dat.lm.ME2)
2.15*2
dat.pooledVar <- (1/(4*nrow(dat.dm))) * (sum((dat.dm$do.dif)^2))
dat.pooledVar <- 1.332 # Their answer is slightly off due to rounding, hard-code answer
dat.meanSE <- round(sqrt(dat.pooledVar/8),2)
dat.effSE <- round(sqrt(dat.pooledVar/2),2)
dat.efftbl$EstStErr <- c(dat.meanSE, rep(dat.effSE, 7))
# Example Ch28 - Fractional factorial experimental designs
# Clear workspace
rm(list=ls())
# Load packages
if(!require("FrF2")){
install.packages("FrF2", dependencies = T); library(FrF2)}
# Enter given data
do.avg <- c(40.20, 45.55, 48.30, 44.8, 46.4, 47.6, 43.4, 52.95)
do.dif <- c(-2.6 ,0.3, -1.0, 2.0, -2.4, -1.4, -4.8, 1.1)
# Create design matrix
dat.ff <- FrF2(8, 3, factor.names = c('S','D','L'),
randomize = F, blocks = 1)
dat.dm <-as.data.frame(attr(dat.ff, 'desnum'))
names(dat.dm) <- names(dat.ff)
dat.dm$Fl <- dat.dm$S * dat.dm$D * dat.dm$L
# Attach observed data
dat.dm$do.avg <- do.avg
dat.dm$do.dif <- do.dif
# Linear models
dat.lm <- lm(do.avg ~ (S + D + L)^3, data = dat.dm)
summary(dat.lm)
dat.lm.ME2 <- lm(do.avg ~ (S + D + L + FL)^2, data = dat.dm)
summary(dat.lm.ME2)
# Calculate estimated effects
dat.estEffects <- round(dat.lm$coefficients * 2, 1)
# Create estimated effects table
effect <- c('Avg + 1234', '1+234', '2+134', '3+124', '4+123', '12+34', '12+24', '23+14')
contFact <- c('Avg(I) + SDLF', 'S+DLF', 'D+SLF', 'L+SDF', 'F+SDL', 'SD+LF', 'SL+DF', 'DL+SF')
estEffect <- c(dat.lm$coefficients[1], dat.estEffects[c(2:4,8,5:7)])
dat.efftbl <- as.data.frame(cbind(effect, contFact, estEffect), row.names = F)
dat.efftbl[8,3] <- -1.2 # Manual fix for rounding error
dat.pooledVar <- (1/(4*nrow(dat.dm))) * (sum((dat.dm$do.dif)^2))
dat.pooledVar
dat.pooledVar <- (1/(4*nrow(dat.dm))) * (sum((dat.dm$do.dif)^2))
dat.pooledVar <- 1.332
dat.efftbl
dat.dm
dat.efftbl
dat.dm$diff
dat.dm$do.dif
(sum((dat.dm$do.dif)^2))
# Example Ch28 - Fractional factorial experimental designs
# Clear workspace
rm(list=ls())
# Load packages
if(!require("FrF2")){
install.packages("FrF2", dependencies = T); library(FrF2)}
# Enter given data
do.avg <- c(40.20, 45.55, 48.30, 44.8, 46.4, 47.6, 43.4, 52.95)
do.dif <- c(-2.6 ,0.3, -1.0, 2.0, -2.4, -1.4, -4.8, 1.1)
# Create design matrix
dat.ff <- FrF2(8, 3, factor.names = c('S','D','L'),
randomize = F, blocks = 1)
dat.dm <-as.data.frame(attr(dat.ff, 'desnum'))
names(dat.dm) <- names(dat.ff)
dat.dm$Fl <- dat.dm$S * dat.dm$D * dat.dm$L
# Attach observed data
dat.dm$do.avg <- do.avg
dat.dm$do.dif <- do.dif
# Linear models
dat.lm <- lm(do.avg ~ (S + D + L)^3, data = dat.dm)
summary(dat.lm)
dat.lm.ME2 <- lm(do.avg ~ (S + D + L + FL)^2, data = dat.dm)
summary(dat.lm.ME2)
# Calculate estimated effects
dat.estEffects <- round(dat.lm$coefficients * 2, 1)
# Create estimated effects table
effect <- c('Avg + 1234', '1+234', '2+134', '3+124', '4+123', '12+34', '12+24', '23+14')
contFact <- c('Avg(I) + SDLF', 'S+DLF', 'D+SLF', 'L+SDF', 'F+SDL', 'SD+LF', 'SL+DF', 'DL+SF')
estEffect <- c(dat.lm$coefficients[1], dat.estEffects[c(2:4,8,5:7)])
dat.efftbl <- as.data.frame(cbind(effect, contFact, estEffect), row.names = F)
dat.efftbl[8,3] <- -1.2 # Manual fix for rounding error
# Calculate the standard errors
dat.pooledVar <- (1/(4*nrow(dat.dm))) * (sum((dat.dm$do.dif)^2))
dat.pooledVar <- 1.332 # Their answer is slightly off due to rounding, hard-code answer
dat.meanSE <- round(sqrt(dat.pooledVar/8),2)
dat.effSE <- round(sqrt(dat.pooledVar/2),2)
dat.efftbl$EstStErr <- c(dat.meanSE, rep(dat.effSE, 7))
dat.dm
summary(dat.lm)
dat.efftbl
# Example Ch28 - Fractional factorial experimental designs
# Clear workspace
rm(list=ls())
# Load packages
if(!require("FrF2")){
install.packages("FrF2", dependencies = T); library(FrF2)}
# Enter given data
do.avg <- c(40.20, 45.55, 48.30, 44.8, 46.4, 47.6, 43.4, 52.95)
do.dif <- c(-2.6 ,0.3, -1.0, 2.0, -2.4, -1.4, -4.8, 1.1)
# Create design matrix
dat.ff <- FrF2(8, 3, factor.names = c('S','D','L'),
randomize = F, blocks = 1)
dat.dm <-as.data.frame(attr(dat.ff, 'desnum'))
names(dat.dm) <- names(dat.ff)
dat.dm$Fl <- dat.dm$S * dat.dm$D * dat.dm$L
# Attach observed data
dat.dm$do.avg <- do.avg
dat.dm$do.dif <- do.dif
# Linear models
dat.lm <- lm(do.avg ~ (S + D + L)^3, data = dat.dm)
summary(dat.lm)
dat.lm.ME2 <- lm(do.avg ~ (S + D + L + FL)^2, data = dat.dm)
summary(dat.lm.ME2)
# Calculate estimated effects
dat.estEffects <- round(dat.lm$coefficients * 2, 1)
# Create estimated effects table
effect <- c('Avg + 1234', '1+234', '2+134', '3+124', '4+123', '12+34', '12+24', '23+14')
contFact <- c('Avg(I) + SDLF', 'S+DLF', 'D+SLF', 'L+SDF', 'F+SDL', 'SD+LF', 'SL+DF', 'DL+SF')
estEffect <- c(dat.lm$coefficients[1], dat.estEffects[c(2:4,8,5:7)])
dat.efftbl <- as.data.frame(cbind(effect, contFact, estEffect), row.names = F)
dat.efftbl[8,3] <- -1.2 # Manual fix for rounding error
# Calculate the standard errors
dat.pooledVar <- (1/(4*nrow(dat.dm))) * (sum((dat.dm$do.dif)^2))
dat.pooledVar <- 1.332 # Their answer is slightly off due to rounding, hard-code answer
dat.meanSE <- round(sqrt(dat.pooledVar/8),2)
dat.effSE <- round(sqrt(dat.pooledVar/2),2)
dat.efftbl$EstStErr <- c(dat.meanSE, rep(dat.effSE, 7))
# Calculate the 95% CI
dat.tstat <- 2.306 # df = 8, a/2 = 0.025
dat.95CI <- dat.tstat * dat.effSE
dat.95CI
# Example Ch20 - Multiple paired comparisons to a control group (Dunnet's Method)
# Clear workspace
rm(list=ls())
# Enter given data
dat.L1 <- c(3.4, 3.0, 3.4, 5.0, 5.1, 5.5, 5.4, 4.2, 3.8, 4.2)
dat.control <- c(4.5, 3.7, 3.8, 3.9, 4.3, 3.9, 4.1, 4.0, 3.0, 4.5)
dat.L3 <- c(5.3, 4.7, 3.6, 5.0, 3.6, 4.5, 4.6, 5.3, 3.9, 4.1)
dat.L4 <- c(3.2, 3.4, 3.1, 3.0, 3.9, 2.0, 1.9, 2.7, 3.8, 4.2)
dat.L5 <- c(3.3, 2.4, 2.7, 3.2, 3.3, 2.9, 4.4, 3.4, 4.8, 3.0)
dat <- setNames(data.frame(matrix(data = c(dat.control, dat.L1, dat.L3, dat.L4, dat.L5),
nrow = length(dat.L1), ncol = 5)),
c('Control', 'L1', 'L3', 'L4', 'L5'))
# Calculate count, mean, variance, and difference for each group
dat.stat <- setNames(data.frame(matrix(nrow = ncol(dat), ncol = 5)),
c('ID', 'Mean', 'Var', 'CntrlDiff', 'n'))
dat.stat$ID <- c('Contrl', 'L1', 'L3', 'L4', 'L5')
dat.stat$Mean <- sapply(dat, mean)
dat.stat$Var <- sapply(dat, var)
dat.stat$CntrlDiff <- dat.stat$Mean - dat.stat$Mean[1]
dat.stat$n <- sapply(dat, length)
# Calculate the pooled variance and standard deviation
dat.stat$pvNumerator <- (dat.stat$n - 1) * dat.stat$Var
pooled.var <- sum(dat.stat$pvNumerator) / (sum(dat.stat$n) - (ncol(dat)))
pooled.sd <- sqrt(pooled.var)
pooled.sd
x <- c(63,78,89,32,77,96,87,67,28,80,100,85,45,92,74,63,42,73,83,87)
cens <- c(F,F,F,T,F,F,F,F,T,F,F,F,T,F,F,F,T,F,F,F)
Cens <- data.frame(x=x,cens=cens)
x.cen <- censummary(Cens$x,Cens$cens)
Cens
x.cen
library(NADA)
x <- c(63,78,89,32,77,96,87,67,28,80,100,85,45,92,74,63,42,73,83,87)
cens <- c(F,F,F,T,F,F,F,F,T,F,F,F,T,F,F,F,T,F,F,F)
Cens <- data.frame(x=x,cens=cens)
x.cen <- censummary(Cens$x,Cens$cens)
x.cen
20/4
library(NADA)
x <- c(63,78,89,32,77,96,87,67,28,80,100,85,45,92,74,63,42,73,83,87)
cens <- c(F,F,F,T,F,F,F,F,T,F,F,F,T,F,F,F,T,F,F,F)
Cens <- data.frame(x=x,cens=cens)
x.cen <- censummary(Cens$x,Cens$cens)
x.cen
4/20
min(x)
max(x)
hist(x)
x.ros <- ros(Cens$x,Cens$cens)
mean(x.ros)
x.ros
x.mle <- cenmle(Cens$x,Cens$cens)
mean(x.mle)
x.km <- cenfit(Cens$x,Cens$cens)
print(mean(x.km))
library(dplyr)
library(mice)
library(foreign) # to import Stata DTA files
library(car)
library(mice)
install.packages(mice)
install.packages('mice')
library(foreign)
library(car)
set.seed(145)
anesimp <- read.dta("anesimputation.dta",
convert.factors = FALSE, missing.type = TRUE)
anesimp <- read.data("anesimputation.dta",
convert.factors = FALSE, missing.type = TRUE)
library(dplyr)
library(mice)
library(foreign)
library(car)
require(rrcovNA)
install.packages(rrcovNA)
install.packages('rrcovNA')
require(rrcovNA)
library(rrcovNA)
data(bush10)
bush10
> head(bush10)
head(bush10)
impSeqRob(bush10)
str(bush10)
library(NADA)
x <- c(63,78,89,32,77,96,87,67,28,80,100,85,45,92,74,63,42,73,83,87)
cens <- c(F,F,F,T,F,F,F,F,T,F,F,F,T,F,F,F,T,F,F,F)
Cens <- data.frame(x=x,cens=cens)
x.cen <- censummary(Cens$x,Cens$cens)
x.ros <- ros(Cens$x,Cens$cens)
x.ros
log(11.6)
library(NADA)
Hg
data(NADA.HgFish)
print(NADA::censtats(Hg$`Hg (Î¼g/L)`,Hg$Cen))
censtats(dat.stack)
1/12
18/12
22.25/12
24.75/12
24/12
10/12
17.25/12
17.5/12
18.25/12
14.75/12
2/12
15/12
21/12
23/12
22/12
13/12
15/12
10/12
2/10
2/12
17/12
22/12
28/12
15/12
16/12
19/12
19/12
16/12
20.5/12
# -------------------------------------------------------------------------- #
# Problem 3
# Clear workspace
rm(list=ls())
# Load packages
# if(!require("FrF2")){
#   install.packages("FrF2", dependencies = T); library(FrF2)}
# Enter data
tm <- c(0.25, 0.5, 1.0, 1.3, 1.8, 2.0, 2.6, 3.0, 4.0, 5.0, 6, 8.0, 9, 9.5, 10, 11, 13)
Y <- c(0.5, 1, 1.1, 1.5, 2.1, 2.5, 3.0, 3.5, 4.4, 6.5, 0, 13.5, 15, 15.5, 16, 16.2, 17)
dat <- data.frame(cbind(tm, Y))
# a. Plot the raw data
# windows()
plot(Y ~ tm, data = dat, pch = 19, xlim = c(0,14), ylim = c(0, 18),
xaxs = 'i', yaxs = 'i',
xlab = 'Time', ylab = 'Algae Concentration')
# b. Get parameter estimates. Explained in handout 'Use of derivatives in R'
# Theta 1: If t approaches infinity, T1 is approximately equal to the largest Y value
T1.start <- max(dat$Y)
T3.start <- 0.0256
T2.start <- 1/(T1.start*T3.start)
y.d1f <- deriv(y~T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm)),c('tm'),c('T1','T2','T3'),func=T)
y.d2f <- deriv(y.d1,c('tm'),c('T1','T2','T3'),func=T)
# Enter data
tm <- c(0.25, 0.5, 1.0, 1.3, 1.8, 2.0, 2.6, 3.0, 4.0, 5.0, 6, 8.0, 9, 9.5, 10, 11, 13)
Y <- c(0.5, 1, 1.1, 1.5, 2.1, 2.5, 3.0, 3.5, 4.4, 6.5, 0, 13.5, 15, 15.5, 16, 16.2, 17)
dat <- data.frame(cbind(tm, Y))
# Enter model
y ~ T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm))
# The model as a function
y.a <- as.function(alist(tm=,T1=,T2=,T3=,T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm))))
y.ac <- Body <- body(y.a)
Args <- args(y.a)
y.ae <- as.expression(y.ac)
# Determine any order derivative >= 1
DD <- function(expr, name, order = 1) {
if(order < 1) stop("'order' must be >= 1")
if(order == 1) D(expr, name)
else DD(D(expr, name), name, order - 1)
}
# DD produces a 'call' - similar to a function but more compact
y.d1 <- DD(y.ae,'tm',order=1)
y.d2 <- DD(y.ae,'tm',order=2)
# derivative evaluation, x is T2, and T1, T3, and tm are defined in the .GlobalEnv
# 1st derivative wrt tm for a given T2
y.e1 <- function(x) {
assign('T2',x,envir=.GlobalEnv)
return(eval(y.d1))
}
# 2nd derivative wrt tm for a given T2
y.e2 <- function(x) {
assign('T2',x,envir=.GlobalEnv)
assign('T3',s0/(T1*T2),envir=.GlobalEnv)
return(eval(y.d2))
}
# 2nd derivative wrt tm for a given tm
y.eTm <- function(x) {
assign('tm',x,envir=.GlobalEnv)
return(eval(y.d2))
}
# Creates functions for 1st and 2nd derivatives
y.d1f <- deriv(y~T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm)),c('tm'),c('T1','T2','T3'),func=T)
y.d2f <- deriv(y.d1,c('tm'),c('T1','T2','T3'),func=T)
?y.d2f
# Problem 3
# Clear workspace
rm(list=ls())
# Load packages
# if(!require("FrF2")){
#   install.packages("FrF2", dependencies = T); library(FrF2)}
# Enter data
tm <- c(0.25, 0.5, 1.0, 1.3, 1.8, 2.0, 2.6, 3.0, 4.0, 5.0, 6, 8.0, 9, 9.5, 10, 11, 13)
Y <- c(0.5, 1, 1.1, 1.5, 2.1, 2.5, 3.0, 3.5, 4.4, 6.5, 0, 13.5, 15, 15.5, 16, 16.2, 17)
dat <- data.frame(cbind(tm, Y))
# a. Plot the raw data
# windows()
plot(Y ~ tm, data = dat, pch = 19, xlim = c(0,14), ylim = c(0, 18),
xaxs = 'i', yaxs = 'i',
xlab = 'Time', ylab = 'Algae Concentration')
# b. Get parameter estimates. Explained in handout 'Use of derivatives in R'
# Theta 1: If t approaches infinity, T1 is approximately equal to the largest Y value
T1.start <- max(dat$Y)
T3.start <- 0.0256
T2.start <- 1/(T1.start*T3.start)
T2.start
1/(17*2.302)
# Theta 1: If t approaches infinity, T1 is approximately equal to the largest Y value
T1.start <- max(dat$Y)
T2.start <- 2.302
T3.start <- 1/(T1.start*T2.start)
frm1 <- Y ~ T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm))
nls.frm1 <- nls(formula = frm1, data = dat, start = list(T1 = T1.start, T2 = T2.start, T3 = T3.start))
summary(nls.frm1)
T3.start
y.a <- as.function(alist(tm=,T1=,T2=,T3=,T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm))))
y.p <- nls(Y ~ y.a(tm,T1,T2,T3), data=dat, start=list(T1=T1.start, T2=T2.start, T3=T3.start))
y.p
dat
# Problem 3
# Clear workspace
rm(list=ls())
# Load packages
# if(!require("FrF2")){
#   install.packages("FrF2", dependencies = T); library(FrF2)}
# Enter data
tm <- c(0.25, 0.5, 1.0, 1.3, 1.8, 2.0, 2.6, 3.0, 4.0, 5.0, 6, 8.0, 9, 9.5, 10, 11, 13)
Y <- c(0.5, 1, 1.1, 1.5, 2.1, 2.5, 3.0, 3.5, 4.4, 6.5, 9, 13.5, 15, 15.5, 16, 16.2, 17)
dat <- data.frame(cbind(tm, Y))
# a. Plot the raw data
# windows()
plot(Y ~ tm, data = dat, pch = 19, xlim = c(0,14), ylim = c(0, 18),
xaxs = 'i', yaxs = 'i',
xlab = 'Time', ylab = 'Algae Concentration')
# b. Get parameter estimates. Explained in handout 'Use of derivatives in R'
# Theta 1: If t approaches infinity, T1 is approximately equal to the largest Y value
T1.start <- max(dat$Y)
T2.start <- 2.302
T3.start <- 1/(T1.start*T2.start)
# c. Estimate T1, T2, and T3.
# Enter formula
frm1 <- Y ~ T1 - (T1+T2)/(1+T2/T1*exp((T1+T2)*T3*tm))
# Run nls analysis to determine model coefficients
nls.frm1 <- nls(formula = frm1, data = dat, start = list(T1 = T1.start, T2 = T2.start, T3 = T3.start))
summary(nls.frm1)
nls.frm1$m$resid()
dat
# Load packages
if(!require("nlstools")){
install.packages("nlstools", dependencies = T); library(nlstools)}
nlsResiduals(nls.frm1)
nlsResiduals(nls.frm1, which = 1)
dat.res <- nlsResiduals(nls.frm1)
windows()
plot(dat.res, which = 0)
plot(dat.res, which = 0, pch = 19, col = 'steelblue3')
plot(dat.res, which = 0, pch = 19)
plot(dat.res, which = 1, pch = 19)
plot(dat.res, which = 5)
plot(dat.res, which = 6)
plot(dat.res, which = 0, pch = 19)
cr=nlsContourRSS(nls.frm1,lseq=200,exp=1.5)
plot(cr, nlev = 0, col = T)
plot(cr, nlev = 0, col = F)
?nlsContourRSS
initLogis <- function(mCall, data, LHS) {
xy <- data.frame(sortedXyData(mCall[["input"]], LHS, data))
if(nrow(xy) < 4)
stop("too few distinct input values to fit a logistic model")
z <- xy[["y"]]
## transform to proportion, i.e. in (0,1) :
rng <- range(z); dz <- diff(rng)
z <- (z - rng[1L] + 0.05 * dz)/(1.1 * dz)
xy[["z"]] <- log(z/(1 - z))		# logit transformation
aux <- coef(lm(x ~ z, xy))
pars <- coef(nls(y ~ 1/(1 + exp((xmid - x)/scal)),
data = xy,
start = list(xmid = aux[[1L]], scal = aux[[2L]]),
algorithm = "plinear"))
setNames(pars[c(".lin", "xmid", "scal")], nm = mCall[c("Asym", "xmid", "scal")])
}
SSlogis <- selfStart(~ Asym/(1 + exp((xmid - x)/scal)),
initial = initLogis,
parameters = c("Asym", "xmid", "scal"))
sslogis
SSlogis
# Problem 2
# Clear workspace
rm(list=ls())
# Load packages
if(!require("nlstools")){
install.packages("nlstools", dependencies = T); library(nlstools)}
# Enter data
tm <- rep(c(0.1, 0.5, 1.0, 1.5, 2.0, 3.0, 4.0), 5)
rc.10 <- c(94, 74, 54, 40, 30, 16, 9)
rc.20 <- c(90, 61, 37, 22, 14, 5, 2)
rc.25 <- c(88, 53, 28, 15, 8, 2, NA)
rc.30 <- c(85, 44, 20, 9, 4, 1, NA)
rc.40 <- c(77, 27, 7, 2, NA, NA, NA)
C <- c(rc.10, rc.20, rc.25, rc.30, rc.40)
Temp <- c(rep(10,7),rep(20,7),rep(25,7),rep(30,7),rep(40,7))
dat <- data.frame(cbind(tm, Temp, C))
# Remove NA values
dat <- dat[which(!is.na(dat$C)),]
# Create models
frm1 <- C ~ Co*exp(-kr*T1^(Temp-20)*tm)
frm2 <- C ~ Co*exp(-A*exp(E/(R*Temp)*tm))
dat
selfStart(~ Co*exp(-A*exp(E/(R*Temp)*tm)), initial = dat, parameters = c('Co', 'A', 'E', 'R'))
getInitial(C ~ SSfrm2(Co, A, E, R), data = dat)
SSfrm2 <- selfStart(~ Co*exp(-A*exp(E/(R*Temp)*tm)), initial = dat, parameters = c('Co', 'A', 'E', 'R'))
getInitial(C ~ SSfrm2(Co, A, E, R), data = dat)
# -------------------------------------------------------------------------- #
# Problem 2
# Clear workspace
rm(list=ls())
# Load packages
if(!require("nlstools")){
install.packages("nlstools", dependencies = T); library(nlstools)}
# Enter data
tm <- rep(c(0.1, 0.5, 1.0, 1.5, 2.0, 3.0, 4.0), 5)
rc.10 <- c(94, 74, 54, 40, 30, 16, 9)
rc.20 <- c(90, 61, 37, 22, 14, 5, 2)
rc.25 <- c(88, 53, 28, 15, 8, 2, NA)
rc.30 <- c(85, 44, 20, 9, 4, 1, NA)
rc.40 <- c(77, 27, 7, 2, NA, NA, NA)
C <- c(rc.10, rc.20, rc.25, rc.30, rc.40)
Temp <- c(rep(10,7),rep(20,7),rep(25,7),rep(30,7),rep(40,7))
dat <- data.frame(cbind(tm, Temp, C))
# Remove NA values
dat <- dat[which(!is.na(dat$C)),]
# Create models
frm1 <- C ~ Co*exp(-kr*T1^(Temp-20)*tm)
frm2 <- C~C0*exp(-A*exp(E/(R*(Temp+273.15)))*tm)
# Form 2 Analysis
# Convert Â°C to Kelvin for model
dat$TempK <- dat$Temp + 273.15
# nls analysis
R <- 1.987
nls.frm2 <- nls(frm2, data=dat ,start=list(C0=100,A=2.e6,E=-9000))
#Alternative version with kelvin temp data
frm2.2 <- C~C0*exp(-A*exp(E/(R*(TempK)))*tm)
nls.frm2.2 <- nls(frm2.2, data=dat ,start=list(C0=100,A=2.e6,E=-9000))
nls.frm2
(10*8) + (11.75*4)
170+127+128
170/425
128/425
127/425
128*0.5
0.05*128
0.10*128
0.20*128
0.40*128
6+6+25+12+51+12+12
.4 + .4 + .6 + .8 + .2 + .8 +.8
# Reach data processing
# Clear workspace
rm(list=ls())
# Load packages
if(!require("dplyr")){
install.packages("dplyr", dependencies = T); library(dplyr)}
# Load data
setwd('c:/Users/A02290896/Documents/Coursework/CEE_6410_Goodrum/Project/Spatial/Projects/')
dat <- read.csv('BR_Network_Reaches.csv', header = T)
# Summarize quality-weighted available habitat for each barrier
dat.sumL <- aggregate(Length_km ~ DS_Barrier_Name, dat, sum)
dat.sumQWL <- aggregate(Length_km_QW ~ DS_Barrier_Name, dat, sum)
sum(dat$Length_km)
sum(dat.sumL$Length_km)
sum(dat$Length_km_QW)
sum(dat.sumQWL$Length_km_QW)
